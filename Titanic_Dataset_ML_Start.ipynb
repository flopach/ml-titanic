{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCmktjVJ3DuA"
   },
   "source": [
    "# Create your first ML Model - Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will explore one of the \"Hello-World\" datasets of machine learning, the Titanic dataset. This was also a challenge on [Kaggle](https://www.kaggle.com/competitions/titanic/overview).\n",
    "\n",
    "Goals:\n",
    "\n",
    "* Create a machine learning model to predict..\n",
    "* Calculate the survival chance if you were on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPh-d0UtTofV"
   },
   "outputs": [],
   "source": [
    "# More information on the dataset https://www.kaggle.com/competitions/titanic/overview\n",
    "test_df = pd.read_csv(\"titanic/test.csv\")\n",
    "train_df = pd.read_csv(\"titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "KfYtczbONmdl",
    "outputId": "71502ca3-51c9-402a-d57f-875ed0d650c1",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Conclusions\n",
    "\n",
    "**Useful Data**:\n",
    "\n",
    "* Age: Age in years\n",
    "* SibSp: # of siblings / spouses aboard the Titanic\n",
    "* Parch: # of parents / children aboard the Titanic\n",
    "* Fare: Passenger fare\n",
    "* Survived: Survived or not\n",
    "* pclass: Ticket class\n",
    "* sex: Sex\n",
    "* embarked: Port of Embarkation\n",
    "\n",
    "**Does it contain important information?**:\n",
    "\n",
    "* PassengerId: Unique ID of a passenger\n",
    "* Name: Name\n",
    "* ticket: Ticket number\n",
    "* cabin: Cabin number\n",
    "\n",
    "\n",
    "**Contains Null-data**:\n",
    "\n",
    "* Age\n",
    "* Cabin\n",
    "* Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(train_df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "m9MxHNmqOOZe",
    "outputId": "ca2624b4-54e6-4e9d-ea6b-b5759e9a09de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Pclass',y='Survived',data=train_df)\n",
    "\n",
    "# Can you explain the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train_df,x=\"Pclass\",y=\"Age\")\n",
    "\n",
    "# Can you explain the boxplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"PassengerId\"].value_counts()\n",
    "\n",
    "# Is this useful data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Ticket\"].value_counts()\n",
    "\n",
    "# Is this useful data? What could we do more to define it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin\"].value_counts()\n",
    "\n",
    "# Is this useful data? What could we do more to define it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Name\"].head(10)\n",
    "\n",
    "# Is this useful data? Can we filter more information from the names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "dsCsVvUgiCMQ",
    "outputId": "8137a929-2dde-4b0a-88ca-42a8adf583d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column named Name_title\n",
    "# We need to do that for the train AND test dataframe\n",
    "\n",
    "both_dfs = [train_df, test_df]\n",
    "\n",
    "for dataset in both_dfs:\n",
    "    dataset[\"Name_title\"] = dataset.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdlzJH8RiZgd"
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our data analysis and feature engineering, we can now prepare our data for pre-processing.\n",
    "\n",
    "**Leave**:\n",
    "\n",
    "* Survived\n",
    "* Sex\n",
    "* Age\n",
    "* SibSp\n",
    "* Parch\n",
    "* Pclass\n",
    "* Fare\n",
    "* Embarked\n",
    "\n",
    "**Drop**:\n",
    "\n",
    "* PassengerId - just the unique ID\n",
    "* Name - Extracting the title, then dropping the whole passenger name\n",
    "* Ticket - maybe extract letters. Drop for now.\n",
    "* Cabin - too many null data rows\n",
    "\n",
    "**Add new column**:\n",
    "    \n",
    "* Name_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60WZ3uuYTrrd",
    "outputId": "6e471c2b-b8be-45b3-e000-d9d544643127"
   },
   "outputs": [],
   "source": [
    "# We need to convert categorical features to numeric values.\n",
    "# Otherwise the machine learning algorithm won't be able to directly take in those features as inputs\n",
    "# We define a 0 for male and a 1 for female\n",
    "# We need to apply this to the train AND test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we know, we have missing Age-values in the train AND test df\n",
    "# Therefore, we apply the mean age of all passengers\n",
    "\n",
    "both_dfs = [train_df, test_df]\n",
    "\n",
    "for dataset in both_dfs:\n",
    "    dataset[\"Age\"] = dataset[\"Age\"].fillna(dataset.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Age\"].isna().sum() # double check if there are any na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Age\"].isna().sum() # double check if there are any na values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one missing fare value in the test dataset, which is not allowed.\n",
    "test_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will just drop this data row from the test_df\n",
    "\n",
    "test_df.dropna(subset=[\"Fare\"],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "GAY9dF-wTufP",
    "outputId": "d57bce87-b917-4e38-c286-47845029618f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# At first we are dropping the 2 datarows where we don't have any data about their embarking\n",
    "# Alternatively we could have filled this value with the most common embarking port\n",
    "\n",
    "train_df.dropna(subset=[\"Embarked\"],inplace = True)\n",
    "\n",
    "# Same as with the genders we need to put this feature into a numeric value\n",
    "\n",
    "cities = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "both_dfs = [train_df, test_df]\n",
    "\n",
    "for dataset in both_dfs:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyS-mRhVUKzK",
    "outputId": "11aabb41-9341-4f21-9399-712e6d632c37"
   },
   "source": [
    "Survived, SibSp, Parch, Pclass don't any processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name & Name_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check our extracted titles again\n",
    "\n",
    "train_df[\"Name_title\"].value_counts() #checking the unique value counts on the train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Name_title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should clean up Name_title a little bit:\n",
    "\n",
    "# aggregating some common titles into a new category\n",
    "# correcting misspelled titles\n",
    "# creating a numeric categorization\n",
    "\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Special\": 5}\n",
    "both_dfs = [train_df, test_df]\n",
    "\n",
    "for dataset in both_dfs:\n",
    "    \n",
    "    # replace titles with a more common title or as Special\n",
    "    dataset['Name_title'] = dataset['Name_title'].replace(['Lady','the Countess','Capt', 'Col','Don', 'Dr','Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Special')\n",
    "    dataset['Name_title'] = dataset['Name_title'].replace('Mlle', 'Miss')\n",
    "    dataset['Name_title'] = dataset['Name_title'].replace('Ms', 'Miss')\n",
    "    dataset['Name_title'] = dataset['Name_title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # convert titles into numbers\n",
    "    dataset['Name_title'] = dataset['Name_title'].map(titles)\n",
    "\n",
    "train_df[\"Name_title\"].value_counts() #checking the new unique value counts on the train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns / data which is not needed\n",
    "# we need to do that on both datasets!\n",
    "    \n",
    "train_df = train_df.drop([\"Name\",\"PassengerId\",\"Ticket\",\"Cabin\"],axis=1)\n",
    "test_df = test_df.drop([\"Name\",\"PassengerId\",\"Ticket\",\"Cabin\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vFKQ0XgR1ka",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any na fields?\n",
    "train_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any na fields?\n",
    "test_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to build the ML model\n",
    "\n",
    "# Fortunately, the dataset is already splitted in a training and test dataset\n",
    "\n",
    "# For training the modeL:\n",
    "x_train = train_df.drop(\"Survived\", axis=1) # hiding the result\n",
    "y_train = train_df[\"Survived\"] #df with the result\n",
    "\n",
    "# For testing the model:\n",
    "x_test = test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a classification problem, let's try with a logistic regression model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(logmodel, x_train, y_train)\n",
    "confusion_matrix(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = logmodel.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass = 1,2,3\n",
    "# Sex = {\"male\": 0, \"female\": 1} \n",
    "# Age = you age\n",
    "# SibSp - with how many siblings did you travel?\n",
    "# Parch - with how many children/parents did you travel?\n",
    "# Fare - How much did you pay for the ticket?\n",
    "# Embarked = {\"Southampton\": 0, \"C\": 1, \"Q\": 2}\n",
    "# Name_title = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Special\": 5}\n",
    "\n",
    "yourself = [[1,1,31,0,0,50,0,1]]\n",
    "\n",
    "predict_yourself = logmodel.predict(yourself)\n",
    "\n",
    "print(predict_yourself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome of this lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks! I hope you've enjoyed this lab!\n",
    "\n",
    "What did you learn today?\n",
    "\n",
    "* Good Data is important!\n",
    "* Data Cleaning + pre-processing takes a lot of time\n",
    "* Domain knowledge is important\n",
    "* Selecting the right model depends on the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic-Dataset-ML-Start.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
